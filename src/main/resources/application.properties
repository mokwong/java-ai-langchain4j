# \u8BBF\u95EE\u7AEF\u53E3
server.port=8080

# langchain4j\u6D4B\u8BD5\u6A21\u578B
langchain4j.open-ai.chat-model.base-url=http://langchain4j.dev/demo/openai/v1
langchain4j.open-ai.chat-model.api-key=demo
langchain4j.open-ai.chat-model.model-name=gpt-4o-mini
# \u6E29\u5EA6\u7CFB\u6570\uFF1A\u53D6\u503C\u8303\u56F4\u901A\u5E38\u5728 0 \u5230 1 \u4E4B\u95F4\u3002\u503C\u8D8A\u9AD8\uFF0C\u6A21\u578B\u7684\u8F93\u51FA\u8D8A\u968F\u673A\u3001\u5929\u9A6C\u884C\u7A7A\u5BCC\u6709\u521B\u9020\u6027\uFF1B
# \u503C\u8D8A\u4F4E\uFF0C\u8F93\u51FA\u8D8A\u786E\u5B9A\u3001\u4FDD\u5B88\u3002\u8FD9\u91CC\u8BBE\u7F6E\u4E3A 0.9\uFF0C\u610F\u5473\u7740\u6A21\u578B\u4F1A\u6709\u4E00\u5B9A\u7684\u968F\u673A\u6027\uFF0C\u751F\u6210\u7684\u56DE\u590D\u53EF\u80FD\u4F1A\u6BD4\u8F83\u591A\u6837\u5316\u3002
langchain4j.open-ai.chat-model.temperature=1
# \u8BF7\u6C42\u548C\u54CD\u5E94\u65E5\u5FD7
langchain4j.open-ai.chat-model.log-requests=true
langchain4j.open-ai.chat-model.log-responses=true

# \u542F\u7528\u65E5\u5FD7debug\u7EA7\u522B
logging.level.root=debug

# ollama
langchain4j.ollama.chat-model.base-url=http://localhost:11434
langchain4j.ollama.chat-model.model-name=llama3.1:8b
langchain4j.ollama.chat-model.timeout=PT60S
# \u8BF7\u6C42\u548C\u54CD\u5E94\u65E5\u5FD7
langchain4j.ollama.chat-model.log-requests=true
langchain4j.ollama.chat-model.log-responses=true


# \u963F\u91CC\u767E\u70BC\u5E73\u53F0\uFF0Cbase-url\u5DF2\u7ECF\u5728starter\u4EE3\u7801\u91CC\u63D0\u4F9B\u4E86\u9ED8\u8BA4\u503C\uFF0C\u6240\u4EE5\u8FD9\u91CC\u4E0D\u9700\u8981\u6307\u5B9A
#langchain4j.community.dashscope.chat-model.api-key=${DASH_SCOPE_API_KEY}
#langchain4j.community.dashscope.chat-model.model-name=qwen-max